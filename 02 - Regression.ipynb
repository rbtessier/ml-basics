{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "*Supervised* machine learning techniques involve training a model to operate on a set of *features* and predict a *label* using a dataset that includes some already-known label values. The training process *fits* the features to the known labels to define a general function that can be applied to new features for which the labels are unknown, and predict them. You can think of this function like this, in which ***y*** represents the label we want to predict and ***x*** represents the features the model uses to predict it.\n",
    "\n",
    "$$y = f(x)$$\n",
    "\n",
    "In most cases, *x* is actually a *vector* that consists of multiple feature values, so to be a little more precise, the function could be expressed like this:\n",
    "\n",
    "$$y = f([x_1, x_2, x_3, ...])$$\n",
    "\n",
    "The goal of training the model is to find a function that performs some kind of calcuation to the *x* values that produces the result *y*. We do this by applying a machine learning *algorithm* that tries to fit the *x* values to a calculation that produces *y* reasonably accurately for all of the cases in the training dataset.\n",
    "\n",
    "There are lots of machine learning algorithms for supervised learning, and they can be broadly divided into two types:\n",
    "\n",
    "- **_Regression_ algorithms**: Algorithms that predict a *y* value that is a numeric value, such as the price of a house or the number of sales transactions.\n",
    "- **_Classification_ algorithms**: Algorithms that predict to which category, or *class*, an observation belongs. The *y* value in a classification model is a vector of probability values between 0 and 1, one for each class, indicating the probability of the observation belonging to each class.\n",
    "\n",
    "In this notebook, we'll focus on *regression*, using an example based on a real study in which data for a bicycle sharing scheme was collected and used to predict the number of rentals based on seasonality and weather conditions. We'll use a simplified version of the dataset from that study.\n",
    "\n",
    "### Explore the Data\n",
    "\n",
    "The first step in any machine learning project is to explore the data that you will use to train a model. The goal of this exploration is to try to understand the relationships between its attributes; in particular, any apparent correlation between the *features* and the *label* your model will try to predict. This may require some work to detect and fix issues in the data (such as dealing with missing values, errors, or outlier values), deriving new feature columns by transforming or combining existing features (a process known as *feature engineering*), *normalizing* numeric features (values you can measure or count) so they're on a similar scale, and *encoding* categorical features (values that represent discrete categories) as numeric indicators.\n",
    "\n",
    "Let's start by loading the bicycle sharing data as a **Pandas** DataFrame and viewing the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant    dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  1/1/2011       1   0     1        0        6           0   \n",
       "1        2  1/2/2011       1   0     1        0        0           0   \n",
       "2        3  1/3/2011       1   0     1        0        1           1   \n",
       "3        4  1/4/2011       1   0     1        0        2           1   \n",
       "4        5  1/5/2011       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  rentals  \n",
       "0           2  0.344167  0.363625  0.805833   0.160446      331  \n",
       "1           2  0.363478  0.353739  0.696087   0.248539      131  \n",
       "2           1  0.196364  0.189405  0.437273   0.248309      120  \n",
       "3           1  0.200000  0.212122  0.590435   0.160296      108  \n",
       "4           1  0.226957  0.229270  0.436957   0.186900       82  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset\n",
    "bike_data = pd.read_csv('data/daily-bike-share.csv')\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of the following columns:\n",
    "\n",
    "- **instant**: A unique row identifier\n",
    "- **dteday**: The date on which the data was observed - in this case, the data was collected daily; so there's one row per date.\n",
    "- **season**: A numerically encoded value indicating the season (1:spring, 2:summer, 3:fall, 4:winter)\n",
    "- **yr**: The year of the study in which the observation was made (the study took place over two years - year 0 represents 2011, and year 1 represents 2012)\n",
    "- **mnth**: The calendar month in which the observation was made (1:January ... 12:December)\n",
    "- **holiday**: A binary value indicating whether or not the observation was made on a public holiday)\n",
    "- **weekday**: The day of the week on which the observation was made (0:Sunday ... 6:Saturday)\n",
    "- **workingday**: A binary value indicating whether or not the day is a working day (not a weekend or holiday)\n",
    "- **weathersit**: A categorical value indicating the weather situation (1:clear, 2:mist/cloud, 3:light rain/snow, 4:heavy rain/hail/snow/fog)\n",
    "- **temp**: The temperature in celsius (normalized)\n",
    "- **atemp**: The apparent (\"feels-like\") temperature in celsius (normalized)\n",
    "- **hum**: The humidity level (normalized)\n",
    "- **windspeed**: The windspeed (normalized)\n",
    "- **rentals**: The number of bicycle rentals recorded.\n",
    "\n",
    "In this dataset, **rentals** represents the label (the *y* value) our model must be trained to predict. The other columns are potential features (*x* values).\n",
    "\n",
    "As mentioned previously, you can perform some *feature engineering* to combine or derive new features. For example, let's add a new column named **day** to the dataframe by extracting the day component from the existing **dteday** column. The new column represents the day of the month from 1 to 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1/6/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>0.233209</td>\n",
       "      <td>0.518261</td>\n",
       "      <td>0.089565</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1/7/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.208839</td>\n",
       "      <td>0.498696</td>\n",
       "      <td>0.168726</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1/8/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.162254</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.266804</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1/9/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.116175</td>\n",
       "      <td>0.434167</td>\n",
       "      <td>0.361950</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1/10/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150833</td>\n",
       "      <td>0.150888</td>\n",
       "      <td>0.482917</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1/11/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.169091</td>\n",
       "      <td>0.191464</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.122132</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1/12/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.160473</td>\n",
       "      <td>0.599545</td>\n",
       "      <td>0.304627</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1/13/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.150883</td>\n",
       "      <td>0.470417</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1/14/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160870</td>\n",
       "      <td>0.188413</td>\n",
       "      <td>0.537826</td>\n",
       "      <td>0.126548</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1/15/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.248112</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.157963</td>\n",
       "      <td>222</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1/16/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>0.234217</td>\n",
       "      <td>0.483750</td>\n",
       "      <td>0.188433</td>\n",
       "      <td>251</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1/17/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.175833</td>\n",
       "      <td>0.176771</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.194017</td>\n",
       "      <td>117</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1/18/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.232333</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.146775</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1/19/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.292174</td>\n",
       "      <td>0.298422</td>\n",
       "      <td>0.741739</td>\n",
       "      <td>0.208317</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1/20/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.261667</td>\n",
       "      <td>0.255050</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.195904</td>\n",
       "      <td>83</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1/21/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.157833</td>\n",
       "      <td>0.457083</td>\n",
       "      <td>0.353242</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1/22/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>93</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1/23/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096522</td>\n",
       "      <td>0.098839</td>\n",
       "      <td>0.436522</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>150</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1/24/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097391</td>\n",
       "      <td>0.117930</td>\n",
       "      <td>0.491739</td>\n",
       "      <td>0.158330</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1/25/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.223478</td>\n",
       "      <td>0.234526</td>\n",
       "      <td>0.616957</td>\n",
       "      <td>0.129796</td>\n",
       "      <td>186</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1/26/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.293850</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1/27/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.113837</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1/28/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.203478</td>\n",
       "      <td>0.223317</td>\n",
       "      <td>0.793043</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1/29/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.651739</td>\n",
       "      <td>0.145365</td>\n",
       "      <td>123</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1/30/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216522</td>\n",
       "      <td>0.250322</td>\n",
       "      <td>0.722174</td>\n",
       "      <td>0.073983</td>\n",
       "      <td>140</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1/31/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.180833</td>\n",
       "      <td>0.186250</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>0.187192</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>2/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.192174</td>\n",
       "      <td>0.234530</td>\n",
       "      <td>0.829565</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instant     dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0         1   1/1/2011       1   0     1        0        6           0   \n",
       "1         2   1/2/2011       1   0     1        0        0           0   \n",
       "2         3   1/3/2011       1   0     1        0        1           1   \n",
       "3         4   1/4/2011       1   0     1        0        2           1   \n",
       "4         5   1/5/2011       1   0     1        0        3           1   \n",
       "5         6   1/6/2011       1   0     1        0        4           1   \n",
       "6         7   1/7/2011       1   0     1        0        5           1   \n",
       "7         8   1/8/2011       1   0     1        0        6           0   \n",
       "8         9   1/9/2011       1   0     1        0        0           0   \n",
       "9        10  1/10/2011       1   0     1        0        1           1   \n",
       "10       11  1/11/2011       1   0     1        0        2           1   \n",
       "11       12  1/12/2011       1   0     1        0        3           1   \n",
       "12       13  1/13/2011       1   0     1        0        4           1   \n",
       "13       14  1/14/2011       1   0     1        0        5           1   \n",
       "14       15  1/15/2011       1   0     1        0        6           0   \n",
       "15       16  1/16/2011       1   0     1        0        0           0   \n",
       "16       17  1/17/2011       1   0     1        1        1           0   \n",
       "17       18  1/18/2011       1   0     1        0        2           1   \n",
       "18       19  1/19/2011       1   0     1        0        3           1   \n",
       "19       20  1/20/2011       1   0     1        0        4           1   \n",
       "20       21  1/21/2011       1   0     1        0        5           1   \n",
       "21       22  1/22/2011       1   0     1        0        6           0   \n",
       "22       23  1/23/2011       1   0     1        0        0           0   \n",
       "23       24  1/24/2011       1   0     1        0        1           1   \n",
       "24       25  1/25/2011       1   0     1        0        2           1   \n",
       "25       26  1/26/2011       1   0     1        0        3           1   \n",
       "26       27  1/27/2011       1   0     1        0        4           1   \n",
       "27       28  1/28/2011       1   0     1        0        5           1   \n",
       "28       29  1/29/2011       1   0     1        0        6           0   \n",
       "29       30  1/30/2011       1   0     1        0        0           0   \n",
       "30       31  1/31/2011       1   0     1        0        1           1   \n",
       "31       32   2/1/2011       1   0     2        0        2           1   \n",
       "\n",
       "    weathersit      temp     atemp       hum  windspeed  rentals  day  \n",
       "0            2  0.344167  0.363625  0.805833   0.160446      331    1  \n",
       "1            2  0.363478  0.353739  0.696087   0.248539      131    2  \n",
       "2            1  0.196364  0.189405  0.437273   0.248309      120    3  \n",
       "3            1  0.200000  0.212122  0.590435   0.160296      108    4  \n",
       "4            1  0.226957  0.229270  0.436957   0.186900       82    5  \n",
       "5            1  0.204348  0.233209  0.518261   0.089565       88    6  \n",
       "6            2  0.196522  0.208839  0.498696   0.168726      148    7  \n",
       "7            2  0.165000  0.162254  0.535833   0.266804       68    8  \n",
       "8            1  0.138333  0.116175  0.434167   0.361950       54    9  \n",
       "9            1  0.150833  0.150888  0.482917   0.223267       41   10  \n",
       "10           2  0.169091  0.191464  0.686364   0.122132       43   11  \n",
       "11           1  0.172727  0.160473  0.599545   0.304627       25   12  \n",
       "12           1  0.165000  0.150883  0.470417   0.301000       38   13  \n",
       "13           1  0.160870  0.188413  0.537826   0.126548       54   14  \n",
       "14           2  0.233333  0.248112  0.498750   0.157963      222   15  \n",
       "15           1  0.231667  0.234217  0.483750   0.188433      251   16  \n",
       "16           2  0.175833  0.176771  0.537500   0.194017      117   17  \n",
       "17           2  0.216667  0.232333  0.861667   0.146775        9   18  \n",
       "18           2  0.292174  0.298422  0.741739   0.208317       78   19  \n",
       "19           2  0.261667  0.255050  0.538333   0.195904       83   20  \n",
       "20           1  0.177500  0.157833  0.457083   0.353242       75   21  \n",
       "21           1  0.059130  0.079070  0.400000   0.171970       93   22  \n",
       "22           1  0.096522  0.098839  0.436522   0.246600      150   23  \n",
       "23           1  0.097391  0.117930  0.491739   0.158330       86   24  \n",
       "24           2  0.223478  0.234526  0.616957   0.129796      186   25  \n",
       "25           3  0.217500  0.203600  0.862500   0.293850       34   26  \n",
       "26           1  0.195000  0.219700  0.687500   0.113837       15   27  \n",
       "27           2  0.203478  0.223317  0.793043   0.123300       38   28  \n",
       "28           1  0.196522  0.212126  0.651739   0.145365      123   29  \n",
       "29           1  0.216522  0.250322  0.722174   0.073983      140   30  \n",
       "30           2  0.180833  0.186250  0.603750   0.187192       42   31  \n",
       "31           2  0.192174  0.234530  0.829565   0.053213       47    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data['day'] = pd.DatetimeIndex(bike_data['dteday']).day\n",
    "bike_data.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's start our analysis of the data by examining a few key descriptive statistics. We can use the dataframe's **describe** method to generate these for the numeric features as well as the **rentals** label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>848.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>686.622488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>315.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>1096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>3410.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             temp       atemp         hum   windspeed      rentals\n",
       "count  731.000000  731.000000  731.000000  731.000000   731.000000\n",
       "mean     0.495385    0.474354    0.627894    0.190486   848.176471\n",
       "std      0.183051    0.162961    0.142429    0.077498   686.622488\n",
       "min      0.059130    0.079070    0.000000    0.022392     2.000000\n",
       "25%      0.337083    0.337842    0.520000    0.134950   315.500000\n",
       "50%      0.498333    0.486733    0.626667    0.180975   713.000000\n",
       "75%      0.655417    0.608602    0.730209    0.233214  1096.000000\n",
       "max      0.861667    0.840896    0.972500    0.507463  3410.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "bike_data[numeric_features + ['rentals']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics reveal some information about the distribution of the data in each of the numeric fields, including the number of observations (there are 731 records), the mean, standard deviation, minimum and maximum values, and the quartile values (the threshold values for 25%, 50% - which is also the median, and 75% of the data). From this, we can see that the mean number of daily rentals is around 848; but there's a comparatively large standard deviation, indicating a lot of variance in the number of rentals per day.\n",
    "\n",
    "We might get a clearer idea of the distribution of rentals values by visualizing the data. Common plot types for visualizing numeric data distributions are *histograms* and *box plots*, so let's use Python's **matplotlib** library to create one of each of these for the **rentals** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This ensures plots are displayed inline in the Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the label column\n",
    "label = bike_data['rentals']\n",
    "\n",
    "# Create a figure for multiple subplots\n",
    "fig = plt.figure(figsize=(9,12))\n",
    "\n",
    "# Plot a histogram\n",
    "a=fig.add_subplot(2, 1, 1)\n",
    "label.plot.hist(color='lightblue', bins=100)\n",
    "# Show the mean and median values on the plot\n",
    "plt.axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "plt.axvline(label.median(), color='green', linestyle='dashed', linewidth=2)\n",
    "a.set_title('Histogram')\n",
    "\n",
    "# Plot a Boxplot\n",
    "a=fig.add_subplot(2, 1, 2)\n",
    "# create a horizontal box plot somit lines up with the histogram for comparison\n",
    "label.plot(kind='box', vert=False)\n",
    "a.set_title('Boxplot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that the number of daily rentals ranges from 0 to just over 3,400. However, the mean (and median) number of daily rentals is closer to the low end of that range, with most of the data between 0 and around 2,200 rentals. The few values above this are shown in the box plot as small circles, indicating that they are *outliers* - in other words, unusually high or low values beyond the typical range of most of the data.\n",
    "\n",
    "We can do the same kind of visual exploration of the numeric features. Let's create a histogram for each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram for each numeric feature\n",
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    feature.hist(color='lightblue', bins=100, ax = ax)\n",
    "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='green', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numeric features seem to be more *normally* distributed, with the mean and median nearer the middle of the range of values, coinciding with where the most commonly occurring values are.\n",
    "\n",
    "> **Note**: The distributions are not truly *normal* in the statistical sense, which would result in a smooth, symmetric \"bell-curve\" histogram with the mean and mode (the most common value) in the center; but they do generally indicate that most of the observations have a value somewhere near the middle.\n",
    "\n",
    "We've explored the distribution of the numeric values in the dataset, but what about the categorical features? These aren't continuous numbers on a scale, so we can't use histograms; but we can plot a bar chart showing the count of each discrete value for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# plot a bar plot for each categorical feature count\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit', 'day']\n",
    "\n",
    "for col in categorical_features:\n",
    "    counts = bike_data[col].value_counts().sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax = ax, color='lightblue')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col) \n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the categorical features show a more or less *uniform* distribution (meaning there's roughly the same number of rows for each category). Exceptions to this include:\n",
    "\n",
    "- **holiday**: There are many fewer days that are holidays than days that aren't.\n",
    "- **workingday**: There are more working days than non-working days.\n",
    "- **weathersit**: Most days are category *1* (clear), with category *2* (mist and cloud) the next most common. There are comaritively few category *3* (light rain or snow) days, and no category *4* (heavy rain, hail, or fog) days at all.\n",
    "\n",
    "Now that we know something about the distribution of the data in our columns, we can start to look for relationships between the features and the **rentals** label we want to be able to predict.\n",
    "\n",
    "For the numeric features, we can create scatter plots that show the intersection of feature and label values. We can also calculate the *correlation* statistic to quantify the apparent relationship.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    label = bike_data['rentals']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label, color='lightblue')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Bike Rentals')\n",
    "    ax.set_title('rentals vs ' + col + '- correlation: ' + str(correlation))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results aren't conclusive, but if you look closely at the scatter plots for **temp** and **atemp**, you can see a vague diagonal trend showing that higher rental counts tend to coincide with higher temperatures; and a correlation value of just over 0.5 for both of these features supports this observation. Conversely, the plots for **hum** and **windspeed** show a slightly negative correlation, indicating that there are fewer rentals on days with high humidity or windspeed.\n",
    "\n",
    "Now let's compare the categorical features to the label. We'll do this by creating box plots that show the distribution of rental counts for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a boxplot for the label by each categorical feature\n",
    "for col in categorical_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    bike_data.boxplot(column = 'rentals', by = col, ax = ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Bike Rentals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show some variance in the relationship between some category values and rentals. For example, there's a clear difference in the distribution of rentals on weekends (**weekday** 0 or 6) and those during the working week (**weekday** 1 to 5). Similarly, there are notable differences for **holiday** and **workingday** categories. There's a noticable trend that shows different rental distributions in summer and fall months compared to spring and winter months. The **weathersit** category also seems to make a difference in rental distribution. The **day** feature we created for the day of the month shows little variation, indicating that it's probably not predictive of the number of rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Regression Model\n",
    "\n",
    "Now that we've explored the data, it's time to use it to train a regression model that uses the features we've identified as potentially predictive to predict the **rentals** label.  The first thing we need to do is to separate the features we want to use to train the model from the label we want it to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X, y = bike_data[['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 1000\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Features:',X[:10], '\\nLabels:', y[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After separating the dataset, we now have numpy arrays named **X** containing the features, and **y** containing the labels.\n",
    "\n",
    "We *could* train a model using all of the data; but it's common practice in supervised learning to split the data into two subsets; a (typically larger) set with which to train the model, and a smaller \"hold-back\" set with which to validate the trained model. This enables us to evaluate how well the model performs when used with the validation dataset by comparing the predicted labels to the known labels.\n",
    "\n",
    "To randomly split the data, we'll use the **train_test_split** function in the **scikit-learn** library. This library is one of the most widely used machine learning packages for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d, rows\\nTest Set: %d rows' % (X_train.size, X_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the following four datasets:\n",
    "\n",
    "- **X_train**: The feature values we'll use to train the model\n",
    "- **y_train**: The corresponding labels we'll use to train the model\n",
    "- **X_test**: The feature values we'll use to validate the model\n",
    "- **y_test**: The corresponding labels we'll use to validate the model\n",
    "\n",
    "Now we're ready to train a model by fitting a suitable regression algorithm to the training data. We'll use the **scikit-learn** implementation of the *linear regression* algorithm, a common starting point for regression that works by trying to find a linear relationship between the *X* values and the *y* label. The resulting model is a function that conceptually defines a line where every possible X and y value combination intersect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a linear regression model on the training set\n",
    "model = LinearRegression(normalize=False).fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Trained Model\n",
    "\n",
    "Now that we've trained the model, we can use it to predict rental counts for the features we held back in our validation dataset. Then we can compare these predictions to the actual label values to evaluate how well (or not!) the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(predictions)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing each prediction with its corresponding \"ground truth\" actual value isn't a very efficient way to determine how well the model is predicting. Let's see if we can get a better indication by visualizing a scatter plot that compares the predictions to the actual labels. We'll also overlay a trend line to get a general sense for how well the predicted labels align with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(y_test, predictions, color=\"lightblue\")\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a definite diagonal trend, and the intersections of the predicted and actual values are generally following the path of the trend line; but there's a fair amount of difference between the ideal function represented by the line and the results. This variance represents the *residuals* of the model - in other words, the difference between the label predicted when the model applies the coefficients it learned during training to the validation data, and the actual value of the validation label. These residuals when evaluated from the validation data indicate the expected level of *error* when the model is used with new data for which the label is unknown.\n",
    "\n",
    "You can quantify the residuals by calculating a number of commonly used evaluation metrics. We'll focus on the following three:\n",
    "\n",
    "- **Mean Square Error (MSE)**: The mean difference between predicted and actual, squared. This yields a relative metric in which the smaller the value, the better the fit of the model\n",
    "- **Root Mean Square Error (RMSE)**: The square root of the MSE. This yields an absolute metric in the same unit as the label (in this case, numbers of rentals). The smaller the value, the better the model (in a simplistic sense, it represents the average number of rentals by which the predictions are wrong!)\n",
    "- **Coefficient of Determination (usually known as *R-squared* or R<sup>2</sup>**: A relative metric in which the higher the value, the better the fit of the model. In essence, this metric represents how much of the variance between predicted and actual label values the model is able to explain.\n",
    "\n",
    "> **Note**: You can find out more about these and other metrics for evaluating regression models in the [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "Let's use Scikit-Learn to calculate these metrics for our model, based on the predictions it generated for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we've quantified the ability of our model to predict the number of rentals. It definitely has *some* predictive power, but we can probably do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "\n",
    "We trained a model with data that was loaded straight from a source file, with only moderately successful results.\n",
    "\n",
    "In practice, it's common to perform some preprocessing of the data to make it easier for the algorithm to fit a model to it. There's a huge range of preprocessing trasformations you can perform to get your data ready for modeling, but we'll limit ourseles to a few common techniques:\n",
    "\n",
    "- Scaling numeric features so they're on the same scale. This prevents feaures with large values from producing coefficients that disproportionately affect the predictions.\n",
    "- Encoding categorical variables. For example, by using a *one hot encoding* technique you can create individual binary (true/false) features for each possible category value.\n",
    "\n",
    "To apply these preprocessing transformations, we'll make use of a Scikit-Learn feature named *pipelines*. These enable us to define a set of preprocessing steps that end with an algorithm. You can then fit the entire pipeline to the data, so that the model encapsulates all of the preprocessing steps as well as the regression algorithm. This is useful, because when we want to use the model to predict values from new data, we need to apply the same transformations (based on the same statistical distributions and catagory encodings used with the training data).\n",
    "\n",
    ">**Note**: The term *pipeline* is used extensively in machine learning, often to mean very different things! In this context, we're using it to refer to pipeline objects in Scikit-Learn, but you may see it used elsewhere to mean someting else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "numeric_features = [6,7,8,9]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = [0,1,2,3,4,5]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', LinearRegression(normalize=False))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the model is trained, including the preprocessing steps. Let's see how it performs with the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(predictions)[:10])\n",
    "print('Actual labels: ' ,y_test[:10])\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "plt.scatter(y_test, predictions, color='lightblue')\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions - Preprocessed')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little better - geat!\n",
    "\n",
    "### Try a Different Algorithm\n",
    "\n",
    "The linear regression algorithm we used to train the model has some predictive capability, but there are many kinds of regression algorithm we could try, including:\n",
    "\n",
    "- **Linear algorithms**: Not just the Linear Regression algorithm we used above (which is technically an *Ordinary Least Squares* algorithm), but other variants such as *Lasso* and *Ridge*.\n",
    "- **Tree-based algorithms**: Algorithms that build a decision tree to reach a prediction\n",
    "- **Ensemble algorithms**: Algorithms that combine the ouputs of multiple base algorithms to improve generalizability.\n",
    "\n",
    "Let's try training our regression model by using an ensemble algorithm called **Gradient Boosting**. We can do this by just changing the last step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('regressor', GradientBoostingRegressor())])\n",
    "\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's see how our ensemble model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "plt.scatter(y_test, predictions, color='lightblue')\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions - Ensemble')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's certainly some improvement!\n",
    "\n",
    "In a real project, you'd likely try a few more algorithms along with more preprocessing; but by now you should have got the general idea. Let's explore how you can use the trained model with new data.\n",
    "\n",
    "### Use the Trained Model\n",
    "\n",
    "First, let's save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './models/bike-share.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load it whenever we need it, and use it to predict labels for new data. This is often called *scoring* or *inferencing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\n",
    "X_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Use the model to predict tomorrow's rentals\n",
    "result = loaded_model.predict(X_new)\n",
    "print('Prediction: {:.0f} rentals'.format(np.round(result[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "The data used in this exercise is derived from [Capital Bikeshare](https://www.capitalbikeshare.com/system-data) and is used in accordance with the published [license agreement](https://www.capitalbikeshare.com/data-license-agreement)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
